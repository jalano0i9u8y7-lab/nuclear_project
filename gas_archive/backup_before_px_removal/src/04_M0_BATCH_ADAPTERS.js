/**
 * ğŸ”Œ M0 Batch Adaptersï¼ˆProvider é©é…å™¨ï¼‰
 * 
 * å¯¦ç¾ Anthropic å’Œ OpenAI çš„ Batch API é©é…å™¨
 * å°‡å…§éƒ¨ Batch Job æ ¼å¼è½‰æ›ç‚º Provider API æ ¼å¼
 * 
 * @version SSOT V8.17
 * @date 2026-01-19
 */

// ==========================================
// Anthropic Batch Adapter
// ==========================================

/**
 * æäº¤ Anthropic Batch
 * 
 * @param {Object} internalJob - å…§éƒ¨ Batch Job ç‰©ä»¶
 * @returns {Object} { provider_batch_id: string, status: string }
 */
function submitAnthropicBatch(internalJob) {
  try {
    const apiKey = getAPIKey("ANTHROPIC");
    const apiUrl = "https://api.anthropic.com/v1/messages/batches";
    
    // è½‰æ›å…§éƒ¨æ ¼å¼ç‚º Anthropic æ ¼å¼
    const anthropicRequests = internalJob.requests.map(req => {
      // æ§‹å»º system blocksï¼ˆæ”¯æ´ prompt cachingï¼‰
      const systemBlocks = [];
      for (const block of req.system_blocks || []) {
        if (typeof block === 'string') {
          // å¦‚æœæ˜¯å­—ä¸²ï¼Œè¦–ç‚ºå¯ cache çš„éœæ…‹å…§å®¹
          systemBlocks.push({
            type: "text",
            text: block,
            cache_control: { type: "ephemeral" }  // â­ æ¨™è¨˜ç‚ºå¯ cache
          });
        } else if (block.type === "text") {
          // å¦‚æœå·²ç¶“æ˜¯ç‰©ä»¶æ ¼å¼ï¼Œä¿ç•™ cache_control
          systemBlocks.push(block);
        }
      }
      
      // æ§‹å»º user message
      const userContent = typeof req.user_payload === 'string' 
        ? req.user_payload 
        : JSON.stringify(req.user_payload, null, 2);
      
      return {
        custom_id: req.custom_id,
        params: {
          model: internalJob.model,
          max_tokens: req.max_output_tokens || 8000,
          temperature: 0.7,
          system: systemBlocks.length > 0 ? systemBlocks : undefined,
          messages: [
            {
              role: "user",
              content: userContent
            }
          ]
        }
      };
    });
    
    // æ§‹å»ºè«‹æ±‚é«”
    const requestBody = {
      requests: anthropicRequests
    };
    
    // ç™¼é€è«‹æ±‚
    const options = {
      method: "POST",
      headers: {
        "x-api-key": apiKey,
        "anthropic-version": "2023-06-01",
        "Content-Type": "application/json"
      },
      payload: JSON.stringify(requestBody),
      muteHttpExceptions: true
    };
    
    const response = UrlFetchApp.fetch(apiUrl, options);
    const responseBody = JSON.parse(response.getContentText());
    
    if (response.getResponseCode() !== 200) {
      throw new Error(`Anthropic Batch API éŒ¯èª¤ï¼š${responseBody.error?.message || response.getResponseCode()}`);
    }
    
    Logger.log(`Anthropic Batch å·²æäº¤ï¼š${responseBody.id} (${internalJob.requests.length} å€‹è«‹æ±‚)`);
    
    return {
      provider_batch_id: responseBody.id,
      status: responseBody.processing_status || "in_progress"
    };
  } catch (error) {
    Logger.log(`æäº¤ Anthropic Batch å¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}

/**
 * æŸ¥è©¢ Anthropic Batch ç‹€æ…‹
 */
function getAnthropicBatchStatus(providerBatchId) {
  try {
    const apiKey = getAPIKey("ANTHROPIC");
    const apiUrl = `https://api.anthropic.com/v1/messages/batches/${providerBatchId}`;
    
    const options = {
      method: "GET",
      headers: {
        "x-api-key": apiKey,
        "anthropic-version": "2023-06-01"
      },
      muteHttpExceptions: true
    };
    
    const response = UrlFetchApp.fetch(apiUrl, options);
    const responseBody = JSON.parse(response.getContentText());
    
    if (response.getResponseCode() !== 200) {
      throw new Error(`Anthropic Batch API éŒ¯èª¤ï¼š${responseBody.error?.message || response.getResponseCode()}`);
    }
    
    return {
      processing_status: responseBody.processing_status,
      request_counts: responseBody.request_counts || {},
      ended_at: responseBody.ended_at,
      expires_at: responseBody.expires_at
    };
  } catch (error) {
    Logger.log(`æŸ¥è©¢ Anthropic Batch ç‹€æ…‹å¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}

/**
 * ç²å– Anthropic Batch çµæœ
 */
function fetchAnthropicBatchResults(providerBatchId) {
  try {
    const apiKey = getAPIKey("ANTHROPIC");
    
    // å…ˆæŸ¥è©¢ Batch ç‹€æ…‹ï¼Œç²å– results_url
    const status = getAnthropicBatchStatus(providerBatchId);
    
    if (status.processing_status !== "ended") {
      throw new Error(`Batch å°šæœªå®Œæˆï¼Œç‹€æ…‹ï¼š${status.processing_status}`);
    }
    
    // å¾ Console æˆ– API ç²å– results_urlï¼ˆé€™è£¡ç°¡åŒ–è™•ç†ï¼‰
    // å¯¦éš›å¯¦ç¾éœ€è¦å…ˆæŸ¥è©¢ Batch è©³æƒ…ç²å– results_url
    const batchDetail = getAnthropicBatchDetail(providerBatchId);
    const resultsUrl = batchDetail.results_url;
    
    if (!resultsUrl) {
      throw new Error("ç„¡æ³•ç²å– Batch çµæœ URL");
    }
    
    // ä¸‹è¼‰çµæœï¼ˆ.jsonl æ ¼å¼ï¼‰
    const options = {
      method: "GET",
      headers: {
        "x-api-key": apiKey,
        "anthropic-version": "2023-06-01"
      },
      muteHttpExceptions: true
    };
    
    const response = UrlFetchApp.fetch(resultsUrl, options);
    const jsonlContent = response.getContentText();
    
    // è§£æ .jsonl æ ¼å¼ï¼ˆæ¯è¡Œä¸€å€‹ JSON ç‰©ä»¶ï¼‰
    const results = [];
    const lines = jsonlContent.split('\n').filter(line => line.trim());
    for (const line of lines) {
      try {
        results.push(JSON.parse(line));
      } catch (e) {
        Logger.log(`è§£æ Batch çµæœè¡Œå¤±æ•—ï¼š${e.message}`);
      }
    }
    
    return results;
  } catch (error) {
    Logger.log(`ç²å– Anthropic Batch çµæœå¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}

/**
 * ç²å– Anthropic Batch è©³æƒ…ï¼ˆåŒ…å« results_urlï¼‰
 */
function getAnthropicBatchDetail(providerBatchId) {
  try {
    const apiKey = getAPIKey("ANTHROPIC");
    const apiUrl = `https://api.anthropic.com/v1/messages/batches/${providerBatchId}`;
    
    const options = {
      method: "GET",
      headers: {
        "x-api-key": apiKey,
        "anthropic-version": "2023-06-01"
      },
      muteHttpExceptions: true
    };
    
    const response = UrlFetchApp.fetch(apiUrl, options);
    const responseBody = JSON.parse(response.getContentText());
    
    if (response.getResponseCode() !== 200) {
      throw new Error(`Anthropic Batch API éŒ¯èª¤ï¼š${responseBody.error?.message || response.getResponseCode()}`);
    }
    
    return responseBody;
  } catch (error) {
    Logger.log(`ç²å– Anthropic Batch è©³æƒ…å¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}

/**
 * å–æ¶ˆ Anthropic Batch
 */
function cancelAnthropicBatch(providerBatchId) {
  try {
    const apiKey = getAPIKey("ANTHROPIC");
    const apiUrl = `https://api.anthropic.com/v1/messages/batches/${providerBatchId}/cancel`;
    
    const options = {
      method: "POST",
      headers: {
        "x-api-key": apiKey,
        "anthropic-version": "2023-06-01"
      },
      muteHttpExceptions: true
    };
    
    const response = UrlFetchApp.fetch(apiUrl, options);
    const responseBody = JSON.parse(response.getContentText());
    
    if (response.getResponseCode() !== 200) {
      throw new Error(`Anthropic Batch API éŒ¯èª¤ï¼š${responseBody.error?.message || response.getResponseCode()}`);
    }
    
    return {
      status: responseBody.processing_status || "canceling"
    };
  } catch (error) {
    Logger.log(`å–æ¶ˆ Anthropic Batch å¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}

// ==========================================
// OpenAI Batch Adapter
// ==========================================

/**
 * æäº¤ OpenAI Batch
 * 
 * @param {Object} internalJob - å…§éƒ¨ Batch Job ç‰©ä»¶
 * @returns {Object} { provider_batch_id: string, status: string }
 */
function submitOpenAIBatch(internalJob) {
  try {
    const apiKey = getAPIKey("OPENAI");
    
    // Step 1: å‰µå»º .jsonl æ–‡ä»¶å…§å®¹
    const jsonlLines = [];
    for (const req of internalJob.requests) {
      // æ§‹å»º messagesï¼ˆOpenAI æ ¼å¼ï¼‰
      const messages = [];
      
      // æ·»åŠ  system messageï¼ˆå›ºå®šæ¨¡æ¿ï¼Œå¯é”åˆ° cached input æ•ˆæœï¼‰
      if (req.system_blocks && req.system_blocks.length > 0) {
        const systemContent = req.system_blocks
          .map(block => typeof block === 'string' ? block : block.text)
          .join('\n\n');
        messages.push({
          role: "system",
          content: systemContent
        });
      }
      
      // æ·»åŠ  user message
      const userContent = typeof req.user_payload === 'string' 
        ? req.user_payload 
        : JSON.stringify(req.user_payload, null, 2);
      messages.push({
        role: "user",
        content: userContent
      });
      
      // æ§‹å»ºè«‹æ±‚é«”ï¼ˆOpenAI Batch æ ¼å¼ï¼‰
      const requestBody = {
        custom_id: req.custom_id,
        method: "POST",
        url: "/v1/chat/completions",
        body: {
          model: internalJob.model,
          messages: messages,
          max_completion_tokens: req.max_output_tokens || 8000,
          temperature: 0.7
        }
      };
      
      jsonlLines.push(JSON.stringify(requestBody));
    }
    
    // Step 2: ä¸Šå‚³ .jsonl æ–‡ä»¶åˆ° OpenAI Files API
    const jsonlContent = jsonlLines.join('\n');
    const blob = Utilities.newBlob(jsonlContent, 'application/x-ndjson', 'batch_input.jsonl');
    
    const uploadUrl = "https://api.openai.com/v1/files";
    const uploadOptions = {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${apiKey}`
      },
      payload: {
        file: blob,
        purpose: "batch"
      },
      muteHttpExceptions: true
    };
    
    const uploadResponse = UrlFetchApp.fetch(uploadUrl, uploadOptions);
    const uploadBody = JSON.parse(uploadResponse.getContentText());
    
    if (uploadResponse.getResponseCode() !== 200) {
      throw new Error(`OpenAI Files API éŒ¯èª¤ï¼š${uploadBody.error?.message || uploadResponse.getResponseCode()}`);
    }
    
    const fileId = uploadBody.id;
    Logger.log(`OpenAI Batch è¼¸å…¥æ–‡ä»¶å·²ä¸Šå‚³ï¼š${fileId}`);
    
    // Step 3: å‰µå»º Batch
    const batchUrl = "https://api.openai.com/v1/batches";
    const batchOptions = {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      payload: JSON.stringify({
        input_file_id: fileId,
        endpoint: "/v1/chat/completions",
        completion_window: "24h"
      }),
      muteHttpExceptions: true
    };
    
    const batchResponse = UrlFetchApp.fetch(batchUrl, batchOptions);
    const batchBody = JSON.parse(batchResponse.getContentText());
    
    if (batchResponse.getResponseCode() !== 200) {
      throw new Error(`OpenAI Batch API éŒ¯èª¤ï¼š${batchBody.error?.message || batchResponse.getResponseCode()}`);
    }
    
    Logger.log(`OpenAI Batch å·²æäº¤ï¼š${batchBody.id} (${internalJob.requests.length} å€‹è«‹æ±‚)`);
    
    return {
      provider_batch_id: batchBody.id,
      status: batchBody.status || "validating"
    };
  } catch (error) {
    Logger.log(`æäº¤ OpenAI Batch å¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}

/**
 * æŸ¥è©¢ OpenAI Batch ç‹€æ…‹
 */
function getOpenAIBatchStatus(providerBatchId) {
  try {
    const apiKey = getAPIKey("OPENAI");
    const apiUrl = `https://api.openai.com/v1/batches/${providerBatchId}`;
    
    const options = {
      method: "GET",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      muteHttpExceptions: true
    };
    
    const response = UrlFetchApp.fetch(apiUrl, options);
    const responseBody = JSON.parse(response.getContentText());
    
    if (response.getResponseCode() !== 200) {
      throw new Error(`OpenAI Batch API éŒ¯èª¤ï¼š${responseBody.error?.message || response.getResponseCode()}`);
    }
    
    return {
      status: responseBody.status,
      request_counts: responseBody.request_counts || {},
      completed_at: responseBody.completed_at,
      failed_at: responseBody.failed_at,
      expired_at: responseBody.expired_at
    };
  } catch (error) {
    Logger.log(`æŸ¥è©¢ OpenAI Batch ç‹€æ…‹å¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}

/**
 * ç²å– OpenAI Batch çµæœ
 */
function fetchOpenAIBatchResults(providerBatchId) {
  try {
    const apiKey = getAPIKey("OPENAI");
    
    // å…ˆæŸ¥è©¢ Batch ç‹€æ…‹ï¼Œç²å– output_file_id
    const status = getOpenAIBatchStatus(providerBatchId);
    
    if (status.status !== "completed") {
      throw new Error(`Batch å°šæœªå®Œæˆï¼Œç‹€æ…‹ï¼š${status.status}`);
    }
    
    // å¾ Batch è©³æƒ…ç²å– output_file_id
    const batchDetail = getOpenAIBatchDetail(providerBatchId);
    const outputFileId = batchDetail.output_file_id;
    
    if (!outputFileId) {
      throw new Error("ç„¡æ³•ç²å– Batch è¼¸å‡ºæ–‡ä»¶ ID");
    }
    
    // ä¸‹è¼‰çµæœæ–‡ä»¶ï¼ˆ.jsonl æ ¼å¼ï¼‰
    const fileUrl = `https://api.openai.com/v1/files/${outputFileId}/content`;
    const options = {
      method: "GET",
      headers: {
        "Authorization": `Bearer ${apiKey}`
      },
      muteHttpExceptions: true
    };
    
    const response = UrlFetchApp.fetch(fileUrl, options);
    const jsonlContent = response.getContentText();
    
    // è§£æ .jsonl æ ¼å¼ï¼ˆæ¯è¡Œä¸€å€‹ JSON ç‰©ä»¶ï¼‰
    const results = [];
    const lines = jsonlContent.split('\n').filter(line => line.trim());
    for (const line of lines) {
      try {
        results.push(JSON.parse(line));
      } catch (e) {
        Logger.log(`è§£æ Batch çµæœè¡Œå¤±æ•—ï¼š${e.message}`);
      }
    }
    
    return results;
  } catch (error) {
    Logger.log(`ç²å– OpenAI Batch çµæœå¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}

/**
 * ç²å– OpenAI Batch è©³æƒ…ï¼ˆåŒ…å« output_file_idï¼‰
 */
function getOpenAIBatchDetail(providerBatchId) {
  try {
    const apiKey = getAPIKey("OPENAI");
    const apiUrl = `https://api.openai.com/v1/batches/${providerBatchId}`;
    
    const options = {
      method: "GET",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      muteHttpExceptions: true
    };
    
    const response = UrlFetchApp.fetch(apiUrl, options);
    const responseBody = JSON.parse(response.getContentText());
    
    if (response.getResponseCode() !== 200) {
      throw new Error(`OpenAI Batch API éŒ¯èª¤ï¼š${responseBody.error?.message || response.getResponseCode()}`);
    }
    
    return responseBody;
  } catch (error) {
    Logger.log(`ç²å– OpenAI Batch è©³æƒ…å¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}

/**
 * å–æ¶ˆ OpenAI Batch
 */
function cancelOpenAIBatch(providerBatchId) {
  try {
    const apiKey = getAPIKey("OPENAI");
    const apiUrl = `https://api.openai.com/v1/batches/${providerBatchId}/cancel`;
    
    const options = {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      muteHttpExceptions: true
    };
    
    const response = UrlFetchApp.fetch(apiUrl, options);
    const responseBody = JSON.parse(response.getContentText());
    
    if (response.getResponseCode() !== 200) {
      throw new Error(`OpenAI Batch API éŒ¯èª¤ï¼š${responseBody.error?.message || response.getResponseCode()}`);
    }
    
    return {
      status: responseBody.status || "cancelling"
    };
  } catch (error) {
    Logger.log(`å–æ¶ˆ OpenAI Batch å¤±æ•—ï¼š${error.message}`);
    throw error;
  }
}
